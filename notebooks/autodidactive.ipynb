{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-30T20:08:08.502768Z",
     "start_time": "2024-11-30T20:08:08.484021Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from RubikCube.src.env import *\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ValuePolicyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ValuePolicyNetwork, self).__init__()\n",
    "\n",
    "        # Define shared layers\n",
    "        self.shared_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(480, 4096),  # Input: 20x24 flattened to 480, then 4096\n",
    "            nn.ELU(),\n",
    "            nn.Linear(4096, 2048),  # 4096 -> 2048\n",
    "            nn.ELU()\n",
    "        )\n",
    "\n",
    "        # Define value head\n",
    "        self.value_head = nn.Sequential(\n",
    "            nn.Linear(2048, 512),  # 2048 -> 512\n",
    "            nn.ELU(),\n",
    "            nn.Linear(512, 1)  # 512 -> 1 (scalar value)\n",
    "        )\n",
    "\n",
    "        # Define policy head\n",
    "        self.policy_head = nn.Sequential(\n",
    "            nn.Linear(2048, 512),  # 2048 -> 512\n",
    "            nn.ELU(),\n",
    "            nn.Linear(512, 12)  # 512 -> 12 (policy logits)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared_out = self.shared_layers(x.unsqueeze(0))\n",
    "        value_out = self.value_head(shared_out)\n",
    "        policy_out = self.policy_head(shared_out)\n",
    "        return value_out, policy_out\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from copy import deepcopy, copy\n",
    "import random\n",
    "import json\n",
    "\n",
    "# Assuming Cube class and move definitions are already provided\n",
    "\n",
    "def generate_samples(k: int, l: int):\n",
    "    samples = []\n",
    "    for _ in range(l):\n",
    "        cube = Cube()\n",
    "        actions = []\n",
    "        # Make random moves up to depth k\n",
    "        for _ in range(k):\n",
    "            move_index = random.randint(0, 11)\n",
    "            cube.move(move_index)\n",
    "            actions.append(move_index)\n",
    "            state = (deepcopy(cube.get_state()), deepcopy(actions))\n",
    "            samples.append(state)\n",
    "\n",
    "    # Transform samples to dictionary format\n",
    "    samples_dict = []\n",
    "    for state, actions in samples:\n",
    "        sample_dict = {\n",
    "            \"state\": [state[0].tolist(), state[1].tolist()],\n",
    "            \"actions\": actions\n",
    "        }\n",
    "        samples_dict.append(sample_dict)\n",
    "\n",
    "    return samples_dict\n",
    "\n",
    "\n",
    "def get_all_childs(cube: Cube):\n",
    "    samples = []\n",
    "    for i in range(len(idx2move)):\n",
    "        current_cube = deepcopy(cube)\n",
    "        actions = []\n",
    "        move_index = random.randint(0, 11)\n",
    "        current_cube.move(move_index)\n",
    "        actions.append(move_index)\n",
    "        state = (deepcopy(current_cube.get_state()), deepcopy(actions))\n",
    "        samples.append(state)\n",
    "\n",
    "    # Transform samples to dictionary format\n",
    "    samples_dict = []\n",
    "    for state, actions in samples:\n",
    "        sample_dict = {\n",
    "            \"state\": [state[0].tolist(), state[1].tolist()],\n",
    "            \"actions\": actions\n",
    "        }\n",
    "        samples_dict.append(sample_dict)\n",
    "\n",
    "    return samples_dict\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-30T20:08:10.267344Z",
     "start_time": "2024-11-30T20:08:10.255581Z"
    }
   },
   "id": "f6069ceace496e25",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "corners, edges = torch.tensor(obj[0]['state'][0]), torch.tensor(obj[0]['state'][1])\n",
    "cube_representation = torch.concat([corners, edges], dim=0)\n",
    "cube_representation_encoded = F.one_hot(cube_representation, num_classes=24)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-30T20:08:10.483623Z",
     "start_time": "2024-11-30T20:08:10.463746Z"
    }
   },
   "id": "d56cc4836dbf50ab",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'state': [[5, 7, 19, 17, 6, 4, 16, 18],\n   [6, 1, 2, 18, 11, 8, 23, 20, 5, 13, 14, 17]],\n  'actions': [3]},\n {'state': [[4, 5, 2, 11, 12, 22, 16, 18],\n   [4, 1, 10, 3, 9, 14, 23, 20, 12, 13, 21, 17]],\n  'actions': [7]},\n {'state': [[0, 1, 2, 3, 12, 13, 14, 15],\n   [0, 1, 2, 3, 9, 10, 21, 22, 12, 13, 14, 15]],\n  'actions': [8]},\n {'state': [[5, 7, 10, 3, 23, 13, 17, 16],\n   [6, 9, 2, 3, 13, 10, 23, 20, 12, 22, 14, 16]],\n  'actions': [4]},\n {'state': [[5, 11, 2, 3, 14, 12, 16, 22],\n   [6, 1, 2, 3, 9, 10, 7, 20, 13, 15, 12, 17]],\n  'actions': [11]},\n {'state': [[7, 6, 2, 20, 12, 9, 16, 18],\n   [7, 1, 21, 3, 9, 2, 23, 20, 12, 13, 10, 17]],\n  'actions': [6]},\n {'state': [[9, 7, 0, 2, 12, 13, 20, 18],\n   [6, 0, 3, 1, 9, 10, 23, 4, 12, 13, 14, 17]],\n  'actions': [0]},\n {'state': [[4, 5, 2, 11, 12, 22, 16, 18],\n   [4, 1, 10, 3, 9, 14, 23, 20, 12, 13, 21, 17]],\n  'actions': [7]},\n {'state': [[5, 7, 19, 17, 6, 4, 16, 18],\n   [6, 1, 2, 18, 11, 8, 23, 20, 5, 13, 14, 17]],\n  'actions': [3]},\n {'state': [[5, 7, 4, 6, 17, 19, 16, 18],\n   [6, 1, 2, 5, 8, 11, 23, 20, 18, 13, 14, 17]],\n  'actions': [2]},\n {'state': [[5, 7, 4, 6, 17, 19, 16, 18],\n   [6, 1, 2, 5, 8, 11, 23, 20, 18, 13, 14, 17]],\n  'actions': [2]},\n {'state': [[5, 7, 19, 17, 6, 4, 16, 18],\n   [6, 1, 2, 18, 11, 8, 23, 20, 5, 13, 14, 17]],\n  'actions': [3]}]"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube = Cube(corners, edges)\n",
    "get_all_childs(cube)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-30T20:08:10.687715Z",
     "start_time": "2024-11-30T20:08:10.665771Z"
    }
   },
   "id": "f53b49194ea7bccb",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "def train_autodidactive(model, optimizer, loss_fn, device, iterations, k):\n",
    "    \"\"\"\n",
    "    Train the model using an autodidactic iteration strategy with weighted samples and tqdm progress bar.\n",
    "\n",
    "    Parameters:\n",
    "        model: The neural network model that predicts value (v) and policy (p).\n",
    "        optimizer: Optimizer for the model.\n",
    "        loss_fn: Loss function for training.\n",
    "        device: Torch device (e.g., 'cuda' or 'cpu').\n",
    "        iterations: Number of iterations to train.\n",
    "        k: Number of scrambled cubes to generate per iteration.\n",
    "    \"\"\"\n",
    "    # Use tqdm to display a progress bar for iterations\n",
    "    bar = tqdm(range(iterations), desc=\"Training Progress\", unit=\"iter\")\n",
    "    running_loss = 0\n",
    "    for iter in bar:\n",
    "        # Generate scrambled cubes\n",
    "        X = generate_samples(k, 1)  # List of scrambled cube states\n",
    "        for dst, xi in enumerate(X):\n",
    "            v_alls, r_alls, weights = [], [], []\n",
    "\n",
    "            # Compute distance-based weight for the current sample\n",
    "            distance_to_solved = dst + 1\n",
    "            weight_xi = 1 / (distance_to_solved + 1e-6)  # Avoid division by zero\n",
    "            weights.append(weight_xi)\n",
    "\n",
    "            # Iterate over all possible actions\n",
    "            for a in idx2move.keys():\n",
    "                # Apply move `a` to the current scrambled cube\n",
    "                cube_xia = Cube(torch.tensor(xi['state'][0]), torch.tensor(xi['state'][1]))\n",
    "                cube_xia.move(a)\n",
    "\n",
    "                # Get cube representation after move\n",
    "                corners, edges = cube_xia.get_state()\n",
    "                cube_representation = torch.concat([corners, edges], dim=0)\n",
    "                cube_representation_encoded = F.one_hot(cube_representation, num_classes=24).float().to(device)\n",
    "\n",
    "                # Predict value (v) and policy (p) using the model\n",
    "                v_xia, p_xia = model(cube_representation_encoded)\n",
    "                v_alls.append(v_xia)\n",
    "\n",
    "                # Calculate reward\n",
    "                \n",
    "                if cube_xia.is_solved():\n",
    "                    r_alls.append(1)  # Reward for solving the cube\n",
    "                else:\n",
    "                    r_alls.append(-1)  # Penalty for not solving the cube\n",
    "\n",
    "            # Compute target values\n",
    "            r_alls = torch.tensor(r_alls).to(device)\n",
    "            v_alls = torch.stack(v_alls)\n",
    "\n",
    "            # Optimal action is the one maximizing reward + value\n",
    "            y_vi = r_alls + v_alls.squeeze()  # R + V for each action\n",
    "            a_star = torch.argmax(y_vi)  # Best action\n",
    "\n",
    "            # Targets for training\n",
    "            y_vi_target = y_vi[a_star]\n",
    "            y_pi_target = F.one_hot(a_star, num_classes=len(idx2move)).float()\n",
    "\n",
    "            # Train the model with weighted loss\n",
    "            optimizer.zero_grad()\n",
    "            v_pred, p_pred = model(cube_representation_encoded)\n",
    "            loss_v = loss_fn(v_pred, y_vi_target.unsqueeze(0))  # Value loss\n",
    "            loss_p = loss_fn(p_pred, y_pi_target.unsqueeze(0))  # Policy loss\n",
    "            loss = (loss_v + loss_p) * weight_xi  # Apply sample weight\n",
    "            running_loss += loss.item()\n",
    "            bar.set_description(f'loss: {running_loss / (iter + 1):4f}')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    print(\"Training completed.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-30T20:11:24.496253Z",
     "start_time": "2024-11-30T20:11:24.486652Z"
    }
   },
   "id": "4c05dc7f9fe96506",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 19.483307:   1%|          | 2605/500000 [01:57<6:14:50, 22.12iter/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[92], line 10\u001B[0m\n\u001B[0;32m      8\u001B[0m k \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m      9\u001B[0m model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 10\u001B[0m \u001B[43mtrain_autodidactive\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterations\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[59], line 67\u001B[0m, in \u001B[0;36mtrain_autodidactive\u001B[1;34m(model, optimizer, loss_fn, device, iterations, k)\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;66;03m# Train the model with weighted loss\u001B[39;00m\n\u001B[0;32m     66\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 67\u001B[0m v_pred, p_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcube_representation_encoded\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     68\u001B[0m loss_v \u001B[38;5;241m=\u001B[39m loss_fn(v_pred, y_vi_target\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m))  \u001B[38;5;66;03m# Value loss\u001B[39;00m\n\u001B[0;32m     69\u001B[0m loss_p \u001B[38;5;241m=\u001B[39m loss_fn(p_pred, y_pi_target\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m))  \u001B[38;5;66;03m# Policy loss\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[1;32mIn[43], line 36\u001B[0m, in \u001B[0;36mValuePolicyNetwork.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     34\u001B[0m shared_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshared_layers(x\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m))\n\u001B[0;32m     35\u001B[0m value_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalue_head(shared_out)\n\u001B[1;32m---> 36\u001B[0m policy_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpolicy_head\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshared_out\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m value_out, policy_out\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    248\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    249\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 250\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    251\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py:561\u001B[0m, in \u001B[0;36mELU.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    560\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 561\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43melu\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1806\u001B[0m, in \u001B[0;36melu\u001B[1;34m(input, alpha, inplace)\u001B[0m\n\u001B[0;32m   1804\u001B[0m     result \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_nn\u001B[38;5;241m.\u001B[39melu_(\u001B[38;5;28minput\u001B[39m, alpha)\n\u001B[0;32m   1805\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1806\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43melu\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1807\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from torch.optim import RMSprop\n",
    "\n",
    "model = ValuePolicyNetwork()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "optimizer = RMSprop(model.parameters(), lr=0.001, alpha=0.99, eps=1e-8)\n",
    "loss_fn = nn.MSELoss()\n",
    "iterations = 500_000\n",
    "k = 1\n",
    "model.to(device)\n",
    "train_autodidactive(model, optimizer, loss_fn, device, iterations, k)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-30T20:25:12.170145Z",
     "start_time": "2024-11-30T20:23:09.476605Z"
    }
   },
   "id": "1a4430c44adfeeb8",
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2.3035]], device='cuda:0', grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube = Cube()\n",
    "cube.move(1)\n",
    "#cube.move(11)\n",
    "corners, edges = cube.get_state()\n",
    "cube_representation = torch.concat([corners, edges], dim=0)\n",
    "cube_representation_encoded = F.one_hot(cube_representation, num_classes=24).float().to(device)\n",
    "model.eval()\n",
    "v, p = model(cube_representation_encoded)\n",
    "v"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-30T20:25:20.281879Z",
     "start_time": "2024-11-30T20:25:20.202939Z"
    }
   },
   "id": "5282722999875a3",
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a964f67b38acf487"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
